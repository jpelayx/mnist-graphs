{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6oLZmENYINqH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision \n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "from torch_geometric.data import InMemoryDataset, Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from skimage.segmentation import slic\n",
        "import skimage as ski\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# on collab: \n",
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "import torchvision \n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "from torch_geometric.data import InMemoryDataset, Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.transforms import ToSLIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import mnist_slic\n",
        "import model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8HQh8qJkKnC"
      },
      "source": [
        "Example for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_LpGX31tkKnD"
      },
      "outputs": [],
      "source": [
        "ds_train = datasets.MNIST(root = \"./data\", train=True, download=True, transform=T.ToTensor())\n",
        "ds_test = datasets.MNIST(root = \"./data\", train=False, download=True, transform=T.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import ConcatDataset\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3 tensor(3)\n"
          ]
        }
      ],
      "source": [
        "ds = ConcatDataset([ds_train, ds_test])\n",
        "y = torch.cat([ds_train.targets, ds_test.targets])\n",
        "print(ds[idx][1], y[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "StratifiedKFold(n_splits=5, random_state=None, shuffle=False)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skf = StratifiedKFold(n_splits=5)\n",
        "skf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_segments = 10\n",
        "compactness = 0.1\n",
        "\n",
        "# features \n",
        "get_avg_color = True\n",
        "get_std_deviation_color = True\n",
        "get_centroid = True\n",
        "get_std_deviation_centroid = True\n",
        "get_num_pixels = False\n",
        "get_avg_color_distance = True\n",
        "get_std_dev_color_distance = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# same as function used in SuperPixelGraphMNIST\n",
        "img, y = ds[1]\n",
        "_, dim0, dim1 = img.shape\n",
        "img_np = img.view(dim0, dim1).numpy()\n",
        "s = slic(img_np, n_segments, compactness, start_label=0)\n",
        "g = ski.future.graph.rag_mean_color(img_np, s)\n",
        "n = g.number_of_nodes()\n",
        "s1 = np.zeros([n, 1])  # for mean color and std deviation\n",
        "s2 = np.zeros([n, 1])  # for std deviation\n",
        "pos1 = np.zeros([n, 2]) # for centroid\n",
        "pos2 = np.zeros([n, 2]) # for centroid std deviation\n",
        "num_pixels = np.zeros([n, 1])\n",
        "for idx in range(dim0 * dim1):\n",
        "        idx_i, idx_j = idx % dim0, int(idx / dim0)\n",
        "        node = s[idx_i][idx_j] - 1\n",
        "        s1[node][0]  += img_np[idx_i][idx_j]\n",
        "        s2[node][0]  += pow(img_np[idx_i][idx_j], 2)\n",
        "        pos1[node][0] += idx_i\n",
        "        pos1[node][1] += idx_j\n",
        "        pos2[node][0] += pow(idx_i, 2)\n",
        "        pos2[node][1] += pow(idx_j, 2)\n",
        "        num_pixels[node][0] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# computing features\n",
        "edge_index = torch.from_numpy(np.array(g.edges).T).to(torch.long)\n",
        "x = []\n",
        "s1 = s1/num_pixels\n",
        "avg_color = s1\n",
        "if get_avg_color:\n",
        "    x.append(torch.from_numpy(avg_color.flatten()).to(torch.float))\n",
        "s2 = s2/num_pixels\n",
        "std_deviation = np.sqrt(s2 - s1*s1)\n",
        "if get_std_deviation_color:\n",
        "    x.append(torch.from_numpy(std_deviation.flatten()).to(torch.float))\n",
        "pos1 = pos1/num_pixels\n",
        "pos = torch.from_numpy(pos1).to(torch.float)\n",
        "if get_centroid:\n",
        "    x.append(pos[:,0])\n",
        "    x.append(pos[:,1])\n",
        "if get_std_deviation_centroid:\n",
        "    pos2 = pos2/num_pixels\n",
        "    std_deviation_centroid = torch.from_numpy(np.abs(np.sqrt(pos2 - pos1*pos1))).to(torch.float)\n",
        "    x.append(std_deviation_centroid[:,0])\n",
        "    x.append(std_deviation_centroid[:,1])\n",
        "if get_num_pixels:\n",
        "    x.append(torch.from_numpy(num_pixels.flatten()).to(torch.float))\n",
        "if get_avg_color_distance or get_std_dev_color_distance:\n",
        "    distances = [[g.edges[u,v]['weight'] for u, v in g.edges(node_idx)] for node_idx in range(n)]\n",
        "    if get_avg_color_distance:\n",
        "        x.append(torch.Tensor([np.average(distance) for distance in distances]))\n",
        "    if get_std_dev_color_distance:\n",
        "        x.append(torch.Tensor([np.std(distance) for distance in distances]))\n",
        "data = Data(x=torch.stack(x, dim=1), edge_index=edge_index, pos=pos, y=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "print(f'Grph with {g.number_of_nodes()} nodes and {g.number_of_edges()} edges')\n",
        "print(f'Label: {data.y}')\n",
        "color_feature = 0\n",
        "pos = dict(zip(range(data.num_nodes), data.pos.numpy()))\n",
        "nx.draw(g, pos=pos, node_color=data.x[:,color_feature])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to test-n75-c0.1-avg_color-std_deviation_color-centroid-std_deviation_centrtoid-avg_color_distance-std_deviation_color_distance/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6aa29a3bab474a02941d4f6b5bb2e821",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/9912422 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting test-n75-c0.1-avg_color-std_deviation_color-centroid-std_deviation_centrtoid-avg_color_distance-std_deviation_color_distance/MNIST/raw/train-images-idx3-ubyte.gz to test-n75-c0.1-avg_color-std_deviation_color-centroid-std_deviation_centrtoid-avg_color_distance-std_deviation_color_distance/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to test-n75-c0.1-avg_color-std_deviation_color-centroid-std_deviation_centrtoid-avg_color_distance-std_deviation_color_distance/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1856fd72077a47b7b451aa181224b867",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/28881 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting test-n75-c0.1-avg_color-std_deviation_color-centroid-std_deviation_centrtoid-avg_color_distance-std_deviation_color_distance/MNIST/raw/train-labels-idx1-ubyte.gz to test-n75-c0.1-avg_color-std_deviation_color-centroid-std_deviation_centrtoid-avg_color_distance-std_deviation_color_distance/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to test-n75-c0.1-avg_color-std_deviation_color-centroid-std_deviation_centrtoid-avg_color_distance-std_deviation_color_distance/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a894e802ab3244ddb0599dc6e5e5934a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1648877 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting test-n75-c0.1-avg_color-std_deviation_color-centroid-std_deviation_centrtoid-avg_color_distance-std_deviation_color_distance/MNIST/raw/t10k-images-idx3-ubyte.gz to test-n75-c0.1-avg_color-std_deviation_color-centroid-std_deviation_centrtoid-avg_color_distance-std_deviation_color_distance/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to test-n75-c0.1-avg_color-std_deviation_color-centroid-std_deviation_centrtoid-avg_color_distance-std_deviation_color_distance/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a10f2d7a7458496789d4b4a80a7a9503",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4542 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting test-n75-c0.1-avg_color-std_deviation_color-centroid-std_deviation_centrtoid-avg_color_distance-std_deviation_color_distance/MNIST/raw/t10k-labels-idx1-ubyte.gz to test-n75-c0.1-avg_color-std_deviation_color-centroid-std_deviation_centrtoid-avg_color_distance-std_deviation_color_distance/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/julia/Documents/cic/petwin/superpixel-gnns/mnist_slic_viz.ipynb Cell 13\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/julia/Documents/cic/petwin/superpixel-gnns/mnist_slic_viz.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m spds \u001b[39m=\u001b[39m mnist_slic\u001b[39m.\u001b[39;49mSuperPixelGraphMNIST(root\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtest-n75-c0.1-avg_color-std_deviation_color-centroid-std_deviation_centrtoid-avg_color_distance-std_deviation_color_distance\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "File \u001b[0;32m~/Documents/cic/petwin/superpixel-gnns/mnist_slic.py:35\u001b[0m, in \u001b[0;36mSuperPixelGraphMNIST.__init__\u001b[0;34m(self, root, n_segments, compactness, features, train)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot \u001b[39m=\u001b[39m get_ds_name(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_segments, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompactness, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain) \u001b[39mif\u001b[39;00m root \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m root\n\u001b[1;32m     34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_pre_loaded \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     36\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_paths[\u001b[39m0\u001b[39m])\n\u001b[1;32m     38\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_stats()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/data/in_memory_dataset.py:50\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, root: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m              transform: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m              pre_transform: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m              pre_filter: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 50\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform, pre_filter)\n\u001b[1;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/data/dataset.py:87\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download()\n\u001b[1;32m     86\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch_geometric/data/dataset.py:170\u001b[0m, in \u001b[0;36mDataset._process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcessing...\u001b[39m\u001b[39m'\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m    169\u001b[0m makedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir)\n\u001b[0;32m--> 170\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess()\n\u001b[1;32m    172\u001b[0m path \u001b[39m=\u001b[39m osp\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir, \u001b[39m'\u001b[39m\u001b[39mpre_transform.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    173\u001b[0m torch\u001b[39m.\u001b[39msave(_repr(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_transform), path)\n",
            "File \u001b[0;32m~/Documents/cic/petwin/superpixel-gnns/mnist_slic.py:156\u001b[0m, in \u001b[0;36mSuperPixelGraphMNIST.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 156\u001b[0m     data, slices \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloadMNIST()\n\u001b[1;32m    157\u001b[0m     torch\u001b[39m.\u001b[39msave((data, slices), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_paths[\u001b[39m0\u001b[39m])\n",
            "File \u001b[0;32m~/Documents/cic/petwin/superpixel-gnns/mnist_slic.py:71\u001b[0m, in \u001b[0;36mSuperPixelGraphMNIST.loadMNIST\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloadMNIST\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     70\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_pre_loaded \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     mnist \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39;49mMNIST(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot, train\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain, download\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, transform\u001b[39m=\u001b[39;49mT\u001b[39m.\u001b[39;49mToTensor())\n\u001b[1;32m     72\u001b[0m     img_total \u001b[39m=\u001b[39m mnist\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     73\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mLoading \u001b[39m\u001b[39m{\u001b[39;00mimg_total\u001b[39m}\u001b[39;00m\u001b[39m images with n_segments = \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_segments\u001b[39m}\u001b[39;00m\u001b[39m ...\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py:104\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_exists():\n\u001b[1;32m    102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataset not found. You can use download=True to download it\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 104\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_data()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py:123\u001b[0m, in \u001b[0;36mMNIST._load_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_load_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    122\u001b[0m     image_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mt10k\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m-images-idx3-ubyte\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 123\u001b[0m     data \u001b[39m=\u001b[39m read_image_file(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_folder, image_file))\n\u001b[1;32m    125\u001b[0m     label_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mt10k\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m-labels-idx1-ubyte\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m     targets \u001b[39m=\u001b[39m read_label_file(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_folder, label_file))\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py:544\u001b[0m, in \u001b[0;36mread_image_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_image_file\u001b[39m(path: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 544\u001b[0m     x \u001b[39m=\u001b[39m read_sn3_pascalvincent_tensor(path, strict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    545\u001b[0m     \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39muint8:\n\u001b[1;32m    546\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx should be of dtype torch.uint8 instead of \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/datasets/mnist.py:526\u001b[0m, in \u001b[0;36mread_sn3_pascalvincent_tensor\u001b[0;34m(path, strict)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[39m# The MNIST format uses the big endian byte order. If the system uses little endian byte order by default,\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[39m# we need to reverse the bytes before we can read them with torch.frombuffer().\u001b[39;00m\n\u001b[1;32m    525\u001b[0m needs_byte_reversal \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mbyteorder \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlittle\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m num_bytes_per_value \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 526\u001b[0m parsed \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrombuffer(\u001b[39mbytearray\u001b[39;49m(data), dtype\u001b[39m=\u001b[39mtorch_type, offset\u001b[39m=\u001b[39m(\u001b[39m4\u001b[39m \u001b[39m*\u001b[39m (nd \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)))\n\u001b[1;32m    527\u001b[0m \u001b[39mif\u001b[39;00m needs_byte_reversal:\n\u001b[1;32m    528\u001b[0m     parsed \u001b[39m=\u001b[39m parsed\u001b[39m.\u001b[39mflip(\u001b[39m0\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "spds = mnist_slic.SuperPixelGraphMNIST(root='test-n75-c0.1-avg_color-std_deviation_color-centroid-std_deviation_centrtoid-avg_color_distance-std_deviation_color_distance')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "data = spds[3]\n",
        "\n",
        "g = to_networkx(data, to_undirected=True)\n",
        "print(f'Grph with {g.number_of_nodes()} nodes and {g.number_of_edges()} edges')\n",
        "print(f'Label: {data.y[0]}')\n",
        "color_feature = 4\n",
        "pos = dict(zip(range(data.num_nodes), data.pos.numpy()))\n",
        "nx.draw(g, pos=pos, node_color=data.x[:,color_feature])\n",
        "# acho que ta virado ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data.num_node_features"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "4e1d9a8909477db77738c33245c29c7265277ef753467dede8cf3f814cde494e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
